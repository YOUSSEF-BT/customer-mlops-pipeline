#!/bin/bash

echo "ğŸš€ DÃ‰PLOIEMENT DU PROJET MLOps COMPLET"
echo "========================================"

# VÃ©rification des prÃ©requis
command -v docker >/dev/null 2>&1 || { echo "âŒ Docker n'est pas installÃ©"; exit 1; }
command -v docker-compose >/dev/null 2>&1 || { echo "âŒ Docker Compose n'est pas installÃ©"; exit 1; }

# CrÃ©ation des dossiers
echo "ğŸ“ CrÃ©ation de la structure..."
mkdir -p {data,models,reports}
mkdir -p airflow/{dags,logs,plugins}
mkdir -p streamlit/models
mkdir -p training_pipeline/src

# GÃ©nÃ©ration de la clÃ© Fernet pour Airflow
echo "ğŸ” GÃ©nÃ©ration des clÃ©s de sÃ©curitÃ©..."
FERNET_KEY=$(python3 -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())" 2>/dev/null || \
             docker run --rm python:3.9-slim python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())")
AIRFLOW_SECRET_KEY=$(openssl rand -hex 32 2>/dev/null || echo "default-secret-key-12345")

# CrÃ©ation du fichier .env
cat > .env << EOL
FERNET_KEY=$FERNET_KEY
AIRFLOW_SECRET_KEY=$AIRFLOW_SECRET_KEY
MLFLOW_TRACKING_URI=http://localhost:5000
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin
EOL

echo "âœ… Fichier .env crÃ©Ã©"

# TÃ©lÃ©chargement des donnÃ©es si elles n'existent pas
if [ ! -f "data/WA_Fn-UseC_-Telco-Customer-Churn.csv" ]; then
    echo "ğŸ“¥ TÃ©lÃ©chargement des donnÃ©es..."
    curl -o data/WA_Fn-UseC_-Telco-Customer-Churn.csv \
    https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv
fi

# Copie du code Streamlit
echo "ğŸ“‹ PrÃ©paration de l'application Streamlit..."
if [ -f "streamlit_app_original.py" ]; then
    echo "ğŸ“„ Utilisation du fichier streamlit_app_original.py"
    cp streamlit_app_original.py streamlit/streamlit_app.py
else
    echo "âš ï¸  streamlit_app_original.py non trouvÃ©, crÃ©ation d'un template..."
    cat > streamlit/streamlit_app.py << 'STREAMLIT_EOF'
import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime

st.set_page_config(page_title="Customer Analytics Dashboard", layout="wide")

st.title("ğŸš€ Customer Analytics & Churn Prediction Platform")
st.markdown("### MLOps Pipeline avec Airflow & MLflow")

# Section informations
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("ğŸ“Š Total Clients", "7,043")
with col2:
    st.metric("ğŸ“ˆ Taux de Churn", "26.54%")
with col3:
    st.metric("ğŸ’° Revenue Annuel", "$5.2M")

st.markdown("---")
st.info("""
ğŸ”§ **Services MLOps en cours d'exÃ©cution:**
- âœ… Airflow: http://localhost:8080 (admin/admin)
- âœ… MLflow: http://localhost:5000
- âœ… Streamlit: http://localhost:8501
- âœ… MinIO: http://localhost:9001 (minioadmin/minioadmin)
""")

# Bouton pour exÃ©cuter le pipeline
if st.button("ğŸ”„ ExÃ©cuter le Pipeline MLOps", type="primary"):
    with st.spinner("ExÃ©cution du pipeline en cours..."):
        st.success("Pipeline dÃ©clenchÃ© avec succÃ¨s!")
        st.info("Consultez Airflow pour suivre l'exÃ©cution")
STREAMLIT_EOF
fi

# Construction des images Docker
echo "ğŸ³ Construction des images Docker..."
docker-compose build

# DÃ©marrage des services
echo "ğŸš€ DÃ©marrage des services..."
docker-compose up -d

# Attente que les services soient prÃªts
echo "â³ Attente du dÃ©marrage des services (60 secondes)..."
sleep 60

# VÃ©rification
echo "ğŸ” VÃ©rification des services..."
docker-compose ps

echo ""
echo "âœ… DÃ‰PLOIEMENT TERMINÃ‰ !"
echo ""
echo "ğŸ“Š ACCÃˆS AUX INTERFACES :"
echo "   - Airflow UI:    http://localhost:8080"
echo "   - MLflow UI:     http://localhost:5000"
echo "   - Streamlit App: http://localhost:8501"
echo "   - MinIO Console: http://localhost:9001"
echo "   - Adminer DB:    http://localhost:8081"
echo ""
echo "ğŸ”‘ CRÃ‰DENTIELS :"
echo "   - Airflow: admin / admin"
echo "   - MinIO:   minioadmin / minioadmin"
echo "   - Adminer: PostgreSQL, serveur=postgres-airflow, user=airflow, password=airflow, db=airflow"
echo ""
echo "ğŸ“‹ COMMANDES UTILES :"
echo "   - Voir les logs: docker-compose logs -f [nom_service]"
echo "   - ArrÃªter: docker-compose down"
echo "   - RedÃ©marrer: docker-compose restart"
echo "   - Forcer le rebuild: docker-compose build --no-cache"
echo ""
echo "ğŸ¯ PROCHAINE Ã‰TAPE :"
echo "   1. AccÃ©dez Ã  Airflow (http://localhost:8080)"
echo "   2. Activez le DAG 'churn_mlops_pipeline'"
echo "   3. DÃ©clenchez une exÃ©cution manuelle"
echo "   4. VÃ©rifiez les modÃ¨les dans MLflow"
echo "   5. Testez l'application Streamlit"
